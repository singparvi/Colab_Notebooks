{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSPT9_214_NK-Solved.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dCJBZF8e6--"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "Edits from Nevi Kaja\n",
        "\n",
        "---\n",
        "\n",
        "# Logistic Regression\n",
        "- do train/validate/test split\n",
        "- begin with baselines for classification\n",
        "- express and explain the intuition and interpretation of Logistic Regression\n",
        "- use sklearn.linear_model.LogisticRegression to fit and interpret Logistic Regression models\n",
        "\n",
        "Logistic regression is the baseline for classification models, as well as a handy way to predict probabilities (since those too live in the unit interval). While relatively simple, it is also the foundation for more sophisticated classification techniques such as neural networks (many of which can effectively be thought of as networks of logistic models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7M2JqGze6_B"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries:\n",
        "- category_encoders\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCWwhL3te6_C"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcJ9CB0Ke6_G"
      },
      "source": [
        "# Do train/validate/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGr0QwRue6_H"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jprCrqTye6_I"
      },
      "source": [
        "### Predict Titanic survival 🚢\n",
        "\n",
        "Kaggle is a platform for machine learning competitions. [Kaggle has used the Titanic dataset](https://www.kaggle.com/c/titanic/data) for their most popular \"getting started\" competition. \n",
        "\n",
        "Kaggle splits the data into train and test sets for participants. Let's load both:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Q0qi9aWVe6_J",
        "outputId": "0ddc9964-abcb-4a6a-a40b-89c559537d53"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(DATA_PATH+'titanic/train.csv')\n",
        "test = pd.read_csv(DATA_PATH+'titanic/test.csv')\n",
        "\n",
        "train.head(5)\n",
        "test.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGX_P7jye6_M"
      },
      "source": [
        "Notice that the train set has one more column than the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmf1bc82e6_N",
        "outputId": "f1199368-82e5-42ec-82f6-27d8dea47b90"
      },
      "source": [
        "train.shape, test.shape\n",
        "\n",
        "#note how the test set does not have a prediction column, it doesnt come with such column from Kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((891, 12), (418, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXfxFMQ3e6_U"
      },
      "source": [
        "Which column is in train but not test? The target!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY98alsfe6_V",
        "outputId": "097f6994-0807-48dc-fb7f-0ba4bafd40af"
      },
      "source": [
        "set(train.columns) - set(test.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Survived'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t3vDs6qzxRE"
      },
      "source": [
        "# NK Notes: validation set is like a pre-test set, you look at your error, but you are still making decisions about your model, you are still tunning your model .\n",
        "NO information should leak from the test set, to the model. The model shouldnt know anything about it. \n",
        "Any choices made based on the test set accuracy \"leak\" information from the test set into the model. Therefore, it is important to keep a separate test set, which is only used for the final evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tub3Cwtde6_Y"
      },
      "source": [
        "### Why doesn't Kaggle give you the target for the test set?\n",
        "\n",
        "#### Rachel Thomas, [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
        "\n",
        "> One great thing about Kaggle competitions is that they force you to think about validation sets more rigorously (in order to do well). For those who are new to Kaggle, it is a platform that hosts machine learning competitions. Kaggle typically breaks the data into two sets you can download:\n",
        ">\n",
        "> 1. a **training set**, which includes the _independent variables,_ as well as the _dependent variable_ (what you are trying to predict).\n",
        ">\n",
        "> 2. a **test set**, which just has the _independent variables._ You will make predictions for the test set, which you can submit to Kaggle and get back a score of how well you did.\n",
        ">\n",
        "> This is the basic idea needed to get started with machine learning, but to do well, there is a bit more complexity to understand. **You will want to create your own training and validation sets (by splitting the Kaggle “training” data). You will just use your smaller training set (a subset of Kaggle’s training data) for building your model, and you can evaluate it on your validation set (also a subset of Kaggle’s training data) before you submit to Kaggle.**\n",
        ">\n",
        "> The most important reason for this is that Kaggle has split the test data into two sets: for the public and private leaderboards. The score you see on the public leaderboard is just for a subset of your predictions (and you don’t know which subset!). How your predictions fare on the private leaderboard won’t be revealed until the end of the competition. The reason this is important is that you could end up overfitting to the public leaderboard and you wouldn’t realize it until the very end when you did poorly on the private leaderboard. Using a good validation set can prevent this. You can check if your validation set is any good by seeing if your model has similar scores on it to compared with on the Kaggle test set. ...\n",
        ">\n",
        "> Understanding these distinctions is not just useful for Kaggle. In any predictive machine learning project, you want your model to be able to perform well on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa_bTdhJe6_Z"
      },
      "source": [
        "### 2-way train/test split is not enough\n",
        "\n",
        "#### Hastie, Tibshirani, and Friedman, [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/), Chapter 7: Model Assessment and Selection\n",
        "\n",
        "> If we are in a data-rich situation, the best approach is to randomly divide the dataset into three parts: a training set, a validation set, and a test set. The training set is used to fit the models; the validation set is used to estimate prediction error for model selection; the test set is used for assessment of the generalization error of the final chosen model. Ideally, the test set should be kept in a \"vault,\" and be brought out only at the end of the data analysis. Suppose instead that we use the test-set repeatedly, choosing the model with the smallest test-set error. Then the test set error of the final chosen model will underestimate the true test error, sometimes substantially.\n",
        "\n",
        "#### Andreas Mueller and Sarah Guido, [Introduction to Machine Learning with Python](https://books.google.com/books?id=1-4lDQAAQBAJ&pg=PA270)\n",
        "\n",
        "> The distinction between the training set, validation set, and test set is fundamentally important to applying machine learning methods in practice. Any choices made based on the test set accuracy \"leak\" information from the test set into the model. Therefore, it is important to keep a separate test set, which is only used for the final evaluation. It is good practice to do all exploratory analysis and model selection using the combination of a training and a validation set, and reserve the test set for a final evaluation - this is even true for exploratory visualization. Strictly speaking, evaluating more than one model on the test set and choosing the better of the two will result in an overly optimistic estimate of how accurate the model is.\n",
        "\n",
        "#### Hadley Wickham, [R for Data Science](https://r4ds.had.co.nz/model-intro.html#hypothesis-generation-vs.hypothesis-confirmation)\n",
        "\n",
        "> There is a pair of ideas that you must understand in order to do inference correctly:\n",
        ">\n",
        "> 1. Each observation can either be used for exploration or confirmation, not both.\n",
        ">\n",
        "> 2. You can use an observation as many times as you like for exploration, but you can only use it once for confirmation. As soon as you use an observation twice, you’ve switched from confirmation to exploration.\n",
        ">\n",
        "> This is necessary because to confirm a hypothesis you must use data independent of the data that you used to generate the hypothesis. Otherwise you will be over optimistic. There is absolutely nothing wrong with exploration, but you should never sell an exploratory analysis as a confirmatory analysis because it is fundamentally misleading.\n",
        ">\n",
        "> If you are serious about doing an confirmatory analysis, one approach is to split your data into three pieces before you begin the analysis.\n",
        "\n",
        "\n",
        "#### Sebastian Raschka, [Model Evaluation](https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html)\n",
        "\n",
        "> Since “a picture is worth a thousand words,” I want to conclude with a figure (shown below) that summarizes my personal recommendations ...\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg\" width=\"600\">\n",
        "\n",
        "Usually, we want to do **\"Model selection (hyperparameter optimization) _and_ performance estimation.\"** (The green box in the diagram.)\n",
        "\n",
        "Therefore, we usually do **\"3-way holdout method (train/validation/test split)\"** or **\"cross-validation with independent test set.\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ2XmCxVe6_a"
      },
      "source": [
        "### What's the difference between Training, Validation, and Testing sets?\n",
        "\n",
        "#### Brandon Rohrer, [Training, Validation, and Testing Data Sets](https://end-to-end-machine-learning.teachable.com/blog/146320/training-validation-testing-data-sets)\n",
        "\n",
        "> The validation set is for adjusting a model's hyperparameters. The testing data set is the ultimate judge of model performance.\n",
        ">\n",
        "> Testing data is what you hold out until very last. You only run your model on it once. You don’t make any changes or adjustments to your model after that. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ltbsa7Ge6_b"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "> You will want to create your own training and validation sets (by splitting the Kaggle “training” data).\n",
        "\n",
        "Do this, using the [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xrkUm_EksxO",
        "outputId": "4cac35b2-a0b3-4fba-b9f6-3ef68e966818"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((891, 12), (418, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "w33KBGGYe6_c",
        "outputId": "7be4fd5d-27b7-434a-97f4-d08fd88c32fa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTcfwRw1kdwX",
        "outputId": "44c25f46-cef1-4c5d-d6da-5b77fe5a7ccb"
      },
      "source": [
        "train, val = train_test_split(train, random_state=42)\n",
        "\n",
        "train_test_split(train, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              " 405          406         0       2  ...  21.0000   NaN         S\n",
              " 547          548         1       2  ...  13.8625   NaN         C\n",
              " 170          171         0       1  ...  33.5000   B19         S\n",
              " 857          858         1       1  ...  26.5500   E17         S\n",
              " 295          296         0       1  ...  27.7208   NaN         C\n",
              " ..           ...       ...     ...  ...      ...   ...       ...\n",
              " 173          174         0       3  ...   7.9250   NaN         S\n",
              " 613          614         0       3  ...   7.7500   NaN         Q\n",
              " 107          108         1       3  ...   7.7750   NaN         S\n",
              " 788          789         1       3  ...  20.5750   NaN         S\n",
              " 816          817         0       3  ...   7.9250   NaN         S\n",
              " \n",
              " [501 rows x 12 columns],\n",
              "      PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              " 651          652         1       2  ...  23.0000   NaN         S\n",
              " 167          168         0       3  ...  27.9000   NaN         S\n",
              " 376          377         1       3  ...   7.2500   NaN         S\n",
              " 392          393         0       3  ...   7.9250   NaN         S\n",
              " 568          569         0       3  ...   7.2292   NaN         C\n",
              " ..           ...       ...     ...  ...      ...   ...       ...\n",
              " 272          273         1       2  ...  19.5000   NaN         S\n",
              " 366          367         1       1  ...  75.2500   D37         C\n",
              " 207          208         1       3  ...  18.7875   NaN         C\n",
              " 676          677         0       3  ...   8.0500   NaN         S\n",
              " 847          848         0       3  ...   7.8958   NaN         C\n",
              " \n",
              " [167 rows x 12 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9CRISKxk6B3",
        "outputId": "4554b7d2-0f27-4282-e5fa-408bea32a110"
      },
      "source": [
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((668, 12), (223, 12), (418, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "z8ls7gEw5oP8",
        "outputId": "1148f328-126e-430a-a47b-99c9543d82b3"
      },
      "source": [
        "train\n",
        "val \n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>3</td>\n",
              "      <td>Spector, Mr. Woolf</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A.5. 3236</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17758</td>\n",
              "      <td>108.9000</td>\n",
              "      <td>C105</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>3</td>\n",
              "      <td>Saether, Mr. Simon Sivertsen</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/O.Q. 3101262</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>3</td>\n",
              "      <td>Ware, Mr. Frederick</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>359309</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>3</td>\n",
              "      <td>Peter, Master. Michael J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2668</td>\n",
              "      <td>22.3583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Pclass  ... Cabin Embarked\n",
              "0            892       3  ...   NaN        Q\n",
              "1            893       3  ...   NaN        S\n",
              "2            894       2  ...   NaN        Q\n",
              "3            895       3  ...   NaN        S\n",
              "4            896       3  ...   NaN        S\n",
              "..           ...     ...  ...   ...      ...\n",
              "413         1305       3  ...   NaN        S\n",
              "414         1306       1  ...  C105        C\n",
              "415         1307       3  ...   NaN        S\n",
              "416         1308       3  ...   NaN        S\n",
              "417         1309       3  ...   NaN        C\n",
              "\n",
              "[418 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpuLCduW5ueE"
      },
      "source": [
        "**it is important that you SAVE your test set! use only once!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxO3WqTde6_f"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C_UYyewe6_g"
      },
      "source": [
        "For your assignment, you'll do a 3-way train/validate/test split.\n",
        "\n",
        "Then next sprint, you'll begin to participate in a private Kaggle challenge, just for your cohort! \n",
        "\n",
        "You will be provided with data split into 2 sets: training and test. You will create your own training and validation sets, by splitting the Kaggle \"training\" data, so you'll end up with 3 sets total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrISCuLXe6_g"
      },
      "source": [
        "# Begin with baselines for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2we0QbI8e6_h"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UThNSZ0Ie6_i"
      },
      "source": [
        "We'll begin with the **majority class baseline.**\n",
        "\n",
        "[Will Koehrsen](https://twitter.com/koehrsen_will/status/1088863527778111488)\n",
        "\n",
        "> A baseline for classification can be the most common class in the training dataset.\n",
        "\n",
        "[*Data Science for Business*](https://books.google.com/books?id=4ZctAAAAQBAJ&pg=PT276), Chapter 7.3: Evaluation, Baseline Performance, and Implications for Investments in Data\n",
        "\n",
        "> For classification tasks, one good baseline is the _majority classifier,_ a naive classifier that always chooses the majority class of the training dataset (see Note: Base rate in Holdout Data and Fitting Graphs). This may seem like advice so obvious it can be passed over quickly, but it is worth spending an extra moment here. There are many cases where smart, analytical people have been tripped up in skipping over this basic comparison. For example, an analyst may see a classification accuracy of 94% from her classifier and conclude that it is doing fairly well—when in fact only 6% of the instances are positive. So, the simple majority prediction classifier also would have an accuracy of 94%. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbuC7E3e6_j"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Mob4Qpe6_k"
      },
      "source": [
        "Determine majority class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhG4SqAPe6_l",
        "outputId": "a0e6ceee-2a3b-4eae-bf78-ef288401f77c"
      },
      "source": [
        "target = 'Survived' #this is the target which we want to classify\n",
        "y_train = train[target]\n",
        "y_train.value_counts(normalize=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.621257\n",
              "1    0.378743\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_fmBjdze6_p"
      },
      "source": [
        "What if we guessed the majority class for every prediction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0ovDkTPe6_q"
      },
      "source": [
        "# Just for demonstration | this is NOT using a model, just saying that we predict based on the most common... \n",
        "majority_class = y_train.mode()[0]  #what is the most common class or the mode ?\n",
        "y_pred = [majority_class] * len(y_train) #multiply this same prediction (mode) with the number of y_train classes you have "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q24Cwc4Ce6_t"
      },
      "source": [
        "#### Use a classification metric: accuracy\n",
        "\n",
        "[Classification metrics are different from regression metrics!](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
        "- Don't use _regression_ metrics to evaluate _classification_ tasks.\n",
        "- **Don't use _classification_ metrics to evaluate _regression_ tasks**\n",
        "\n",
        "[Accuracy](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score) is a common metric for classification. Accuracy is the [\"proportion of correct classifications\"](https://en.wikipedia.org/wiki/Confusion_matrix): the number of correct predictions divided by the total number of predictions. **bold text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA3TW7vme6_u"
      },
      "source": [
        "What is the baseline accuracy if we guessed the majority class for every prediction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ4gqmK4e6_v"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSBEOS22e6_y",
        "outputId": "6c586bed-cf9b-40a0-eded-8e43b4ca6ed3"
      },
      "source": [
        "# Training accuracy of majority class baseline = frequency of majority class (aka base rate)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6212574850299402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZV6PoPprnr6",
        "outputId": "7026e315-43c9-4167-f321-b6908c525bac"
      },
      "source": [
        "# Validation accuracy of majority class baseline =  usually similar to Train accuracy\n",
        "y_val = val[target]\n",
        "y_pred = [majority_class] * len(y_val)\n",
        "accuracy_score(y_val, y_pred)\n",
        "\n",
        "#why does this happen ?  the validation set might have a slightly different split then the trainint set "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.600896860986547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP2FlNOGe6_1"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCCQYyr9e6_2"
      },
      "source": [
        "In your assignment, your Sprint Challenge, and your upcoming Kaggle challenge, you'll begin with the majority class baseline. How quickly can you beat this baseline?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLsZ3VSe6_3"
      },
      "source": [
        "# Express and explain the intuition and interpretation of Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NELOOMQke6_4"
      },
      "source": [
        "## Overview\n",
        "\n",
        "To help us get an intuition for *Logistic* Regression, let's start by trying *Linear* Regression instead, and see what happens..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129lMJcve6_4"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayXS_3TWe6_5"
      },
      "source": [
        "### Linear Regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ABLok5sDe6_6",
        "outputId": "4466b5c9-92b8-4e8e-a5f2-2c7498c53615"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>447.450599</td>\n",
              "      <td>0.378743</td>\n",
              "      <td>2.333832</td>\n",
              "      <td>29.421343</td>\n",
              "      <td>0.553892</td>\n",
              "      <td>0.372754</td>\n",
              "      <td>32.179397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>258.038366</td>\n",
              "      <td>0.485437</td>\n",
              "      <td>0.823707</td>\n",
              "      <td>14.526010</td>\n",
              "      <td>1.185279</td>\n",
              "      <td>0.795588</td>\n",
              "      <td>51.604012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>221.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>452.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>673.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   668.000000  668.000000  668.000000  ...  668.000000  668.000000  668.000000\n",
              "mean    447.450599    0.378743    2.333832  ...    0.553892    0.372754   32.179397\n",
              "std     258.038366    0.485437    0.823707  ...    1.185279    0.795588   51.604012\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     221.750000    0.000000    2.000000  ...    0.000000    0.000000    7.925000\n",
              "50%     452.500000    0.000000    3.000000  ...    0.000000    0.000000   14.400000\n",
              "75%     673.500000    1.000000    3.000000  ...    1.000000    0.000000   30.500000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71QBx8S1e6_9",
        "outputId": "6e000f49-1062-4c71-de2c-c154d3b9b89d"
      },
      "source": [
        "# 1. Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate this class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# 3. Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Pclass', 'Age', 'Fare']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "# 4. Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train)\n",
        "\n",
        "# 5. Apply the model to new data.\n",
        "# The predictions look like this ...  \n",
        "linear_reg.predict(X_val_imputed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23418773,  0.414959  ,  0.29142187,  0.60240298,  0.33464094,\n",
              "        0.70204713,  0.22782825,  0.32690633,  0.31821017,  0.70458858,\n",
              "        0.60612454,  0.12990727,  0.2428592 ,  0.22348605,  0.38340904,\n",
              "        0.73591945,  0.57199051,  0.22789544,  0.44401679,  0.53784936,\n",
              "        0.26446032,  0.60380195,  0.298096  ,  0.2925248 ,  0.23355499,\n",
              "        0.37571072,  0.5643901 ,  0.41708001,  0.41611588,  0.21728567,\n",
              "        0.29813129,  0.27780501,  0.63815283,  0.22765856,  0.30499631,\n",
              "        0.24982192,  0.65180034,  0.22782825,  0.63451413,  0.22795194,\n",
              "        0.53575051,  0.23006821,  0.22808277,  0.22782825,  0.12860643,\n",
              "        0.34079898,  0.298354  ,  0.27232222,  0.26374274,  0.5157593 ,\n",
              "        0.40205002,  0.53938723,  0.1736849 ,  0.83797194, -0.01176533,\n",
              "        0.7565994 ,  0.4082248 ,  0.68352778,  0.39693048,  0.29811721,\n",
              "        0.28456041,  0.54381014,  0.44831187,  0.63410525,  0.22782825,\n",
              "        0.23986996,  0.53575051,  0.2307717 ,  0.31103413,  0.52646321,\n",
              "        0.46178026,  0.91162438,  0.6606025 ,  0.61815779,  0.27115922,\n",
              "        0.19014386,  0.22056436,  0.70408319,  0.36994065,  0.16042859,\n",
              "        0.34530614,  0.42842738,  0.6549822 ,  0.22781764,  0.459167  ,\n",
              "        0.37411125,  0.69758253,  0.65651261,  0.55433999,  0.22740404,\n",
              "        0.37618792,  0.38530828,  0.42687469,  0.2278106 ,  0.22795194,\n",
              "        0.23748825,  0.53111516,  0.12317307,  0.38340904,  0.24425774,\n",
              "        0.40130951,  0.18973024,  0.75956181,  0.16946402,  0.22081888,\n",
              "        0.25762364,  0.37853082,  0.52639588,  0.22541617,  0.56717219,\n",
              "        0.65622744,  0.2874821 ,  0.68770686,  0.59011085,  0.80026912,\n",
              "        0.29305149,  0.36151242,  0.38330299,  0.49126225,  0.12530478,\n",
              "        0.46968095,  0.65947149,  0.45212543,  0.63382514,  0.25717823,\n",
              "        0.59706775,  0.50226235,  0.71581246,  0.23351961,  0.28479373,\n",
              "        0.22793786,  0.23418773,  0.41668172,  0.39629502,  0.52856293,\n",
              "        0.33063225,  0.70618438,  0.23068686,  0.14295145,  0.31326827,\n",
              "        0.28511892,  0.34056477,  0.43728259,  0.38770413,  0.18145839,\n",
              "        0.41342135,  0.42381421,  0.17926221,  0.73641945,  0.13664146,\n",
              "        0.22864484,  0.26412096,  0.30478064,  0.2417421 ,  0.22808277,\n",
              "        0.22723436,  0.26918447,  0.22786006,  0.39443832,  0.21703822,\n",
              "        0.26726187,  0.63463551,  0.36320646,  0.68182452,  0.22842917,\n",
              "        0.42510028,  0.46883255,  0.65611078,  0.27792871,  0.18966661,\n",
              "        0.70910646,  0.50462453,  0.59019569,  0.37170901,  0.31094573,\n",
              "        0.22738283,  0.1901121 ,  0.50923771,  0.40661373,  0.52801311,\n",
              "        0.47095356,  0.21061154,  0.25095664,  0.40551086,  0.85861682,\n",
              "        0.52972581,  0.44303761,  0.22795194,  0.64222874,  0.34300388,\n",
              "        0.19744015,  0.40299653,  0.31088566,  0.23215036,  0.30015961,\n",
              "        0.65089911,  0.74737355,  0.39687743,  0.7441172 ,  0.37183989,\n",
              "        0.01388824,  0.22470563,  0.58994204,  0.00326201,  0.29083155,\n",
              "        0.24022201,  0.2321362 ,  0.66961709,  0.23351961,  0.0895021 ,\n",
              "        0.80785398,  0.22350726,  0.6643675 ,  0.22780704,  0.2428592 ,\n",
              "        0.4237939 ,  0.47190808,  0.51886995,  0.46851445,  0.22740404,\n",
              "        0.22795194,  0.46421937,  0.31531504])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGz68G68e7AB",
        "outputId": "bf7ec458-bd82-4998-f651-dd3dc3404659"
      },
      "source": [
        "# Get coefficients\n",
        "pd.Series(linear_reg.coef_, features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass   -0.195429\n",
              "Age      -0.006734\n",
              "Fare      0.000848\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_rbelJQe7AE",
        "outputId": "ecd9b759-0f1f-42a8-eabf-cdabe351d06c"
      },
      "source": [
        "test_case = [[1, 5, 500]]  # 1st class, 5-year old, Rich\n",
        "linear_reg.predict(test_case)\n",
        "#this is more extreme case ... regression is continuoous, so gives us continous numbers on predictions "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.20077135])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDX3r_T4e7AH"
      },
      "source": [
        "### Logistic Regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjmLzHM6ht0x"
      },
      "source": [
        "Lets do the same thing using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFY2k1_we7AH",
        "outputId": "e2a5fe47-98af-44eb-8566-94319bfe5dbe"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "#yes it is still a linear model\n",
        "log_reg = LogisticRegression()\n",
        "#log_reg = LogisticRegression(solver='lbfgs')\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_imputed, y_val))\n",
        "\n",
        "#this is already better then baseline!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7354260089686099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH0p5JY3e7AK",
        "outputId": "77b24c57-b49b-41dc-e925-72501986cbde"
      },
      "source": [
        "# The predictions look like this\n",
        "log_reg.predict(X_val_imputed)\n",
        "#discrete classes!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8LKZ1OFe7AN",
        "outputId": "491a2f0b-bf1e-4eb3-e642-d21bdb0bec4b"
      },
      "source": [
        "log_reg.predict(test_case)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPDI2fUAe7AP",
        "outputId": "b3e4ac28-674c-4207-d97a-810688973baf"
      },
      "source": [
        "log_reg.predict_proba(test_case)\n",
        "#logistic regression calculated predicted probabilityies for each class and chooses the highest \n",
        "#first number is predicted probability for class 0, and second is predicted probability for class 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02418324, 0.97581676]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Eot75He7AR",
        "outputId": "d0c49733-1c19-4c77-f180-536b0371019c"
      },
      "source": [
        "# What's the math?\n",
        "log_reg.coef_[0]\n",
        "#coefficient are similiar to linear regression, the first coefficient belongs to the first feature and its negative in this case, so if you were first class you more likely to survavie then second class etc\n",
        "#when the sign is negative then they are negatively correlated (lower  age, higher probability so survive ) ... higher fare, higher probability to survive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.84573613, -0.03196344,  0.0049728 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVLrpQR9e7AW",
        "outputId": "5c3282a1-08db-437d-fd9e-9fe820e9a196"
      },
      "source": [
        "log_reg.intercept_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.21676629])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-CTi2Ome7AY"
      },
      "source": [
        "# The logistic sigmoid \"squishing\" function, implemented to accept numpy arrays\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e**(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OtQA9WPe7Ab",
        "outputId": "8b3c9e18-1bab-4671-8764-4a31ddc335b2"
      },
      "source": [
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97581676]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY2nJGyXvQ4R",
        "outputId": "581ac550-9d26-4d17-b190-bea85a2b8a58"
      },
      "source": [
        "log_reg.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.84573613, -0.03196344,  0.0049728 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdut-GUuvaOg",
        "outputId": "d5150d4d-27f8-426d-aa53-54b6a8c8c390"
      },
      "source": [
        "test_case"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 5, 500]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYioVaR-vb44",
        "outputId": "2e26754f-4b1d-4cb9-c43d-e76b5302055d"
      },
      "source": [
        "2.21676629 + -0.84573613*1 + -0.03196344*5 + 0.0049728*500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.69761296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VraRezgGvldC",
        "outputId": "e58929a7-ce12-44c8-cc13-aa67f6274356"
      },
      "source": [
        "sigmoid(2.21676629 + -0.84573613*1 + -0.03196344*5 + 0.0049728*500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9758167120565335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVKg8pc4vvtt",
        "outputId": "82a10806-35c7-4782-9fb4-0783d1885996"
      },
      "source": [
        "np.e ** -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36787944117144233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POjcHPYee7Ae"
      },
      "source": [
        "So, clearly a more appropriate model in this situation! For more on the math, [see this Wikipedia example](https://en.wikipedia.org/wiki/Logistic_regression#Probability_of_passing_an_exam_versus_hours_of_study)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub3Yi9MKo947"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMsZxzZeqKSy"
      },
      "source": [
        "Linear Regression to Logistic Regression tutorial: https://www.kdnuggets.com/2020/03/linear-logistic-regression-explained.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2kM9Are7Ae"
      },
      "source": [
        "# Use sklearn.linear_model.LogisticRegression to fit and interpret Logistic Regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijPtf4Mae7Af"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Now that we have more intuition and interpretation of Logistic Regression, let's use it within a realistic, complete scikit-learn workflow, with more features and transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JgYWHX6e7Ag"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Select these features: `['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']`\n",
        "\n",
        "(Why shouldn't we include the `Name` or `Ticket` features? What would happen here?)  \n",
        "\n",
        "Fit this sequence of transformers & estimator:\n",
        "\n",
        "- [category_encoders.one_hot.OneHotEncoder](https://contrib.scikit-learn.org/categorical-encoding/onehot.html)\n",
        "- [sklearn.impute.SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
        "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "- [sklearn.linear_model.LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
        "\n",
        "Get validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dab3RcQBsf3P",
        "outputId": "f86ac77d-1f2d-4dc5-8c79-da2edaf2abe7"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>299</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Saalfeld, Mr. Adolphe</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19988</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>C106</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>885</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Sutehall, Mr. Henry Jr</td>\n",
              "      <td>male</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SOTON/OQ 392076</td>\n",
              "      <td>7.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>248</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Hamalainen, Mrs. William (Anna)</td>\n",
              "      <td>female</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>250649</td>\n",
              "      <td>14.5000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>479</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Karlsson, Mr. Nils August</td>\n",
              "      <td>male</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>350060</td>\n",
              "      <td>7.5208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>306</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...      Fare    Cabin  Embarked\n",
              "298          299         1       1  ...   30.5000     C106         S\n",
              "884          885         0       3  ...    7.0500      NaN         S\n",
              "247          248         1       2  ...   14.5000      NaN         S\n",
              "478          479         0       3  ...    7.5208      NaN         S\n",
              "305          306         1       1  ...  151.5500  C22 C26         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wct4fKPre7Ah",
        "outputId": "abad99f5-74aa-43d6-988b-0f522e96a65a"
      },
      "source": [
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((668, 7), (668,), (223, 7), (223,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2enyJWZ3Xx5"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2D71sAva3nPz",
        "outputId": "3c0e3638-0287-4fe2-8545-c99d2a20abb9"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>14.5000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5208</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex    Age  SibSp  Parch      Fare Embarked\n",
              "298       1    male    NaN      0      0   30.5000        S\n",
              "884       3    male  25.00      0      0    7.0500        S\n",
              "247       2  female  24.00      0      2   14.5000        S\n",
              "478       3    male  22.00      0      0    7.5208        S\n",
              "305       1    male   0.92      1      2  151.5500        S"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "DrqdBSX73pv5",
        "outputId": "d3401b2f-bacd-4aeb-fda1-17451580d23b"
      },
      "source": [
        "X_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15.2458</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.2417</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
              "709       3    male   NaN      1      1  15.2458        C\n",
              "439       2    male  31.0      0      0  10.5000        S\n",
              "840       3    male  20.0      0      0   7.9250        S\n",
              "720       2  female   6.0      0      1  33.0000        S\n",
              "39        3  female  14.0      1      0  11.2417        C"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcMniFtC382M",
        "outputId": "5301439e-0b8d-4074-c468-9f7d6a5e23a9"
      },
      "source": [
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "\n",
        "#lets do one hot encoding on EMBARKED and SEX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dYUObXn4UYj"
      },
      "source": [
        "X_val_encoded = encoder.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "UZ_GCKip4_2Q",
        "outputId": "3f63519b-356c-47eb-dcfc-a523163b657a"
      },
      "source": [
        "X_train_encoded.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_nan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>14.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>22.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5208</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  Sex_male  Sex_female  ...  Embarked_C  Embarked_Q  Embarked_nan\n",
              "298       1         1           0  ...           0           0             0\n",
              "884       3         1           0  ...           0           0             0\n",
              "247       2         0           1  ...           0           0             0\n",
              "478       3         1           0  ...           0           0             0\n",
              "305       1         1           0  ...           0           0             0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "ILtYjIEa5VQ4",
        "outputId": "f4db0cac-2243-4178-cbb6-c126a6d28ee4"
      },
      "source": [
        "X_val_encoded.head()\n",
        "#note how Age has a NaN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_nan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15.2458</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.2417</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  Sex_male  Sex_female  ...  Embarked_C  Embarked_Q  Embarked_nan\n",
              "709       3         1           0  ...           1           0             0\n",
              "439       2         1           0  ...           0           0             0\n",
              "840       3         1           0  ...           0           0             0\n",
              "720       2         0           1  ...           0           0             0\n",
              "39        3         0           1  ...           1           0             0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2zFdxxd4thC"
      },
      "source": [
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "\n",
        "#replace missing values with their mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiJbKKIi5DLe",
        "outputId": "87fe14fd-dd93-4471-c7f3-5c3242ac9037"
      },
      "source": [
        "X_train_imputed[:5] #this is an arrey thats why we cant do .head  because its not a DF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.        ,   1.        ,   0.        ,  29.42134328,\n",
              "          0.        ,   0.        ,  30.5       ,   1.        ,\n",
              "          0.        ,   0.        ,   0.        ],\n",
              "       [  3.        ,   1.        ,   0.        ,  25.        ,\n",
              "          0.        ,   0.        ,   7.05      ,   1.        ,\n",
              "          0.        ,   0.        ,   0.        ],\n",
              "       [  2.        ,   0.        ,   1.        ,  24.        ,\n",
              "          0.        ,   2.        ,  14.5       ,   1.        ,\n",
              "          0.        ,   0.        ,   0.        ],\n",
              "       [  3.        ,   1.        ,   0.        ,  22.        ,\n",
              "          0.        ,   0.        ,   7.5208    ,   1.        ,\n",
              "          0.        ,   0.        ,   0.        ],\n",
              "       [  1.        ,   1.        ,   0.        ,   0.92      ,\n",
              "          1.        ,   2.        , 151.55      ,   1.        ,\n",
              "          0.        ,   0.        ,   0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BPScfIv5Zr3",
        "outputId": "7b29b92b-dd88-42bf-a2b2-7d1ffab8d897"
      },
      "source": [
        "X_val_imputed[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.        ,  1.        ,  0.        , 29.42134328,  1.        ,\n",
              "         1.        , 15.2458    ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [ 2.        ,  1.        ,  0.        , 31.        ,  0.        ,\n",
              "         0.        , 10.5       ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [ 3.        ,  1.        ,  0.        , 20.        ,  0.        ,\n",
              "         0.        ,  7.925     ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [ 2.        ,  0.        ,  1.        ,  6.        ,  0.        ,\n",
              "         1.        , 33.        ,  1.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [ 3.        ,  0.        ,  1.        , 14.        ,  1.        ,\n",
              "         0.        , 11.2417    ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "iyhXB-mru--O",
        "outputId": "86d451dc-32ba-4071-b6ac-c3cd6729f76b"
      },
      "source": [
        "pd.DataFrame(X_train_imputed, columns=X_train_encoded.columns)\n",
        "#note how Age is back"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_nan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.421343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5208</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.421343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.1083</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>77.2875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>668 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  Sex_male  Sex_female  ...  Embarked_C  Embarked_Q  Embarked_nan\n",
              "0       1.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "1       3.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "2       2.0       0.0         1.0  ...         0.0         0.0           0.0\n",
              "3       3.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "4       1.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "..      ...       ...         ...  ...         ...         ...           ...\n",
              "663     3.0       0.0         1.0  ...         0.0         0.0           0.0\n",
              "664     1.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "665     3.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "666     1.0       0.0         1.0  ...         0.0         0.0           0.0\n",
              "667     1.0       1.0         0.0  ...         0.0         0.0           0.0\n",
              "\n",
              "[668 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuPPYyfY51qx"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "\n",
        "#last step is to use a standart scaler which Standardize features by removing the mean and scaling to unit variance\n",
        "#now we got numbers which are standarized in a similiar scale... it allows us to compare the coefficients because everyone is in a simmiliar playing field"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGHOjMA46nYY",
        "outputId": "1e20a311-6a49-4564-8cda-c141e40da19c"
      },
      "source": [
        "X_train_scaled[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.62051704,  0.72224656, -0.72224656,  0.        , -0.46765956,\n",
              "        -0.46887833, -0.0325683 ,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [ 0.80934914,  0.72224656, -0.72224656, -0.34010987, -0.46765956,\n",
              "        -0.46887833, -0.48733085,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [-0.40558395, -1.38456873,  1.38456873, -0.41703442, -0.46765956,\n",
              "         2.04687047, -0.34285405,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [ 0.80934914,  0.72224656, -0.72224656, -0.57088354, -0.46765956,\n",
              "        -0.46887833, -0.4782007 ,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [-1.62051704,  0.72224656, -0.72224656, -2.19245317,  0.37665554,\n",
              "         2.04687047,  2.31493731,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3QW2m9E6pYT",
        "outputId": "fe0c6620-d451-4079-8052-533b0c21aa0c"
      },
      "source": [
        "X_val_scaled[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.80934914,  0.72224656, -0.72224656,  0.        ,  0.37665554,\n",
              "         0.78899607, -0.32839086, -1.66553634,  2.1701156 , -0.30835364,\n",
              "        -0.05479966],\n",
              "       [-0.40558395,  0.72224656, -0.72224656,  0.12143747, -0.46765956,\n",
              "        -0.46887833, -0.42042549,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [ 0.80934914,  0.72224656, -0.72224656, -0.72473265, -0.46765956,\n",
              "        -0.46887833, -0.4703621 ,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [-0.40558395, -1.38456873,  1.38456873, -1.80167643, -0.46765956,\n",
              "         0.78899607,  0.01591384,  0.60040719, -0.46080495, -0.30835364,\n",
              "        -0.05479966],\n",
              "       [ 0.80934914, -1.38456873,  1.38456873, -1.18627998,  0.37665554,\n",
              "        -0.46887833, -0.40604181, -1.66553634,  2.1701156 , -0.30835364,\n",
              "        -0.05479966]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ7ZAv526ztI",
        "outputId": "4a129c6a-1902-47f8-9f4e-ffb34c9bf621"
      },
      "source": [
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "#we use the training set which is encoded, imputed and scaled... "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr2AdqG4653z",
        "outputId": "adba9ae1-8d8f-49fa-a925-db116fa51240"
      },
      "source": [
        "# One way...\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "accuracy_score(y_val, y_pred)\n",
        "#note how we improved the accuracy score significiantly "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8071748878923767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fvueYNd7BD3",
        "outputId": "1af5d2d2-897f-4ae2-f9b9-4ece3135680c"
      },
      "source": [
        "# Shortcut\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8071748878923767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV65krdve7Aj"
      },
      "source": [
        "Plot coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2UjsiJqze7Ak",
        "outputId": "aa48577d-24af-4279-d8af-478c9973cdfe"
      },
      "source": [
        "%matplotlib inline\n",
        "coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)\n",
        "coefficients.sort_values().plot.barh(); #bar charts\n",
        "#here we can see the true effect of coefficient compared with others because the data is scaled \n",
        "#women and children first hypothesis is true ... if you were a female you had a higher probability to survive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcB4I2o8e7Am"
      },
      "source": [
        "Generate [Kaggle](https://www.kaggle.com/c/titanic) submission:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5dDA2Vde7An"
      },
      "source": [
        "X_test = test[features]\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "X_test_imputed = imputer.transform(X_test_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "y_pred = model.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhZbbdYj8wup"
      },
      "source": [
        "submission = test[['PassengerId']].copy() #get the id and the prediction \n",
        "submission['Survived'] = y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmEs7pf_89x1"
      },
      "source": [
        "submission.to_csv('titanic-submission-01.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z8xNchKe7Aq"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You'll use Logistic Regression for your assignment, your Sprint Challenge, and optionally for your first model in our Kaggle challenge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDHWuWIte7Ar"
      },
      "source": [
        "# Review\n",
        "\n",
        "For your assignment, you'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- Begin with baselines for classification.\n",
        "- Use scikit-learn for logistic regression.\n",
        "- Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- Get your model's test accuracy. (One time, at the end.)\n",
        "- Commit your notebook to your fork of the GitHub repo.\n",
        "- Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ02Drn1e7As"
      },
      "source": [
        "# Sources\n",
        "- Brandon Rohrer, [Training, Validation, and Testing Data Sets](https://end-to-end-machine-learning.teachable.com/blog/146320/training-validation-testing-data-sets)\n",
        "- Hadley Wickham, [R for Data Science](https://r4ds.had.co.nz/model-intro.html#hypothesis-generation-vs.hypothesis-confirmation), Hypothesis generation vs. hypothesis confirmation\n",
        "- Hastie, Tibshirani, and Friedman, [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/), Chapter 7: Model Assessment and Selection\n",
        "- Mueller and Guido, [Introduction to Machine Learning with Python](https://books.google.com/books?id=1-4lDQAAQBAJ&pg=PA270), Chapter 5.2.2: The Danger of Overfitting the Parameters and the Validation Set\n",
        "- Provost and Fawcett, [Data Science for Business](https://books.google.com/books?id=4ZctAAAAQBAJ&pg=PT276), Chapter 7.3: Evaluation, Baseline Performance, and Implications for Investments in Data\n",
        "- Rachel Thomas, [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)\n",
        "- Sebastian Raschka, [Model Evaluation](https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html)\n",
        "- Will Koehrsen, [\"A baseline for classification can be the most common class in the training dataset.\"](https://twitter.com/koehrsen_will/status/1088863527778111488)"
      ]
    }
  ]
}